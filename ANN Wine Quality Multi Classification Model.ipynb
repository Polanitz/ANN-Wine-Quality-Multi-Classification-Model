{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wine Quality Classification using Keras Sequential ANN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.36</td>\n",
       "      <td>20.7</td>\n",
       "      <td>0.045</td>\n",
       "      <td>45.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>1.0010</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>8.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.049</td>\n",
       "      <td>14.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.9940</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.49</td>\n",
       "      <td>9.5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.1</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.40</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.050</td>\n",
       "      <td>30.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.9951</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.44</td>\n",
       "      <td>10.1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.9956</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.9956</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.0              0.27         0.36            20.7      0.045   \n",
       "1            6.3              0.30         0.34             1.6      0.049   \n",
       "2            8.1              0.28         0.40             6.9      0.050   \n",
       "3            7.2              0.23         0.32             8.5      0.058   \n",
       "4            7.2              0.23         0.32             8.5      0.058   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 45.0                 170.0   1.0010  3.00       0.45   \n",
       "1                 14.0                 132.0   0.9940  3.30       0.49   \n",
       "2                 30.0                  97.0   0.9951  3.26       0.44   \n",
       "3                 47.0                 186.0   0.9956  3.19       0.40   \n",
       "4                 47.0                 186.0   0.9956  3.19       0.40   \n",
       "\n",
       "   alcohol  quality  \n",
       "0      8.8        6  \n",
       "1      9.5        6  \n",
       "2     10.1        6  \n",
       "3      9.9        6  \n",
       "4      9.9        6  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('winequality-white.csv', index_col=None, sep=\";\")\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fixed acidity           0\n",
       "volatile acidity        0\n",
       "citric acid             0\n",
       "residual sugar          0\n",
       "chlorides               0\n",
       "free sulfur dioxide     0\n",
       "total sulfur dioxide    0\n",
       "density                 0\n",
       "pH                      0\n",
       "sulphates               0\n",
       "alcohol                 0\n",
       "quality                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_dataset = dataset.iloc[:,0:-1]\n",
    "target_dataset = dataset.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.36</td>\n",
       "      <td>20.7</td>\n",
       "      <td>0.045</td>\n",
       "      <td>45.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>1.00100</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>8.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.049</td>\n",
       "      <td>14.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.99400</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.49</td>\n",
       "      <td>9.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.1</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.40</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.050</td>\n",
       "      <td>30.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.99510</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.44</td>\n",
       "      <td>10.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.99560</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.99560</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4893</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.29</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.039</td>\n",
       "      <td>24.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>0.99114</td>\n",
       "      <td>3.27</td>\n",
       "      <td>0.50</td>\n",
       "      <td>11.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4894</th>\n",
       "      <td>6.6</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.36</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.047</td>\n",
       "      <td>57.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>0.99490</td>\n",
       "      <td>3.15</td>\n",
       "      <td>0.46</td>\n",
       "      <td>9.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4895</th>\n",
       "      <td>6.5</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.19</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.041</td>\n",
       "      <td>30.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>0.99254</td>\n",
       "      <td>2.99</td>\n",
       "      <td>0.46</td>\n",
       "      <td>9.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4896</th>\n",
       "      <td>5.5</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.022</td>\n",
       "      <td>20.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.98869</td>\n",
       "      <td>3.34</td>\n",
       "      <td>0.38</td>\n",
       "      <td>12.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4897</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.020</td>\n",
       "      <td>22.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0.98941</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.32</td>\n",
       "      <td>11.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4898 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0               7.0              0.27         0.36            20.7      0.045   \n",
       "1               6.3              0.30         0.34             1.6      0.049   \n",
       "2               8.1              0.28         0.40             6.9      0.050   \n",
       "3               7.2              0.23         0.32             8.5      0.058   \n",
       "4               7.2              0.23         0.32             8.5      0.058   \n",
       "...             ...               ...          ...             ...        ...   \n",
       "4893            6.2              0.21         0.29             1.6      0.039   \n",
       "4894            6.6              0.32         0.36             8.0      0.047   \n",
       "4895            6.5              0.24         0.19             1.2      0.041   \n",
       "4896            5.5              0.29         0.30             1.1      0.022   \n",
       "4897            6.0              0.21         0.38             0.8      0.020   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                    45.0                 170.0  1.00100  3.00       0.45   \n",
       "1                    14.0                 132.0  0.99400  3.30       0.49   \n",
       "2                    30.0                  97.0  0.99510  3.26       0.44   \n",
       "3                    47.0                 186.0  0.99560  3.19       0.40   \n",
       "4                    47.0                 186.0  0.99560  3.19       0.40   \n",
       "...                   ...                   ...      ...   ...        ...   \n",
       "4893                 24.0                  92.0  0.99114  3.27       0.50   \n",
       "4894                 57.0                 168.0  0.99490  3.15       0.46   \n",
       "4895                 30.0                 111.0  0.99254  2.99       0.46   \n",
       "4896                 20.0                 110.0  0.98869  3.34       0.38   \n",
       "4897                 22.0                  98.0  0.98941  3.26       0.32   \n",
       "\n",
       "      alcohol  \n",
       "0         8.8  \n",
       "1         9.5  \n",
       "2        10.1  \n",
       "3         9.9  \n",
       "4         9.9  \n",
       "...       ...  \n",
       "4893     11.2  \n",
       "4894      9.6  \n",
       "4895      9.4  \n",
       "4896     12.8  \n",
       "4897     11.8  \n",
       "\n",
       "[4898 rows x 11 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 5, 7, 8, 4, 3, 9], dtype=int64)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.quality.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.quality.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['fixed acidity', 'volatile acidity', 'citric acid',\n",
       "       'residual sugar', 'chlorides', 'free sulfur dioxide',\n",
       "       'total sulfur dioxide', 'density', 'pH', 'sulphates', 'alcohol'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_cols = feature_dataset.columns.values\n",
    "all_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
    "#create the specs for the column transformer\n",
    "#the function \"make_column_transformer\" will create the column transformer object\n",
    "#categories=\"auto\" and drop=\"first\" tell the encoder to create k-1 columns, rather than k columns\n",
    "# and that the first category will be the implicit category\n",
    "# preprocess = make_column_transformer(\n",
    "#     (['''select columns to be scaled'''], StandardScaler()))\n",
    "# )\n",
    "\n",
    "# option 1 \n",
    "# preprocess = make_column_transformer((StandardScaler(), all_cols))\n",
    "\n",
    "# option 2\n",
    "cat_cols = []\n",
    "preprocess = make_column_transformer(\n",
    "    (OneHotEncoder(categories=\"auto\", drop=\"first\"), cat_cols),\n",
    "    remainder = StandardScaler())\n",
    "\n",
    "\n",
    "\n",
    "#fit_transform is the function that fits the transformations to the data and then does the transformation\n",
    "X = preprocess.fit_transform(feature_dataset)\n",
    "\n",
    "# one hot encode the target\n",
    "\n",
    "\n",
    "dummy_y = pd.get_dummies(dataset.quality)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       6\n",
       "1       6\n",
       "2       6\n",
       "3       6\n",
       "4       6\n",
       "       ..\n",
       "4893    6\n",
       "4894    5\n",
       "4895    6\n",
       "4896    7\n",
       "4897    6\n",
       "Name: quality, Length: 4898, dtype: int64"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4893</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4894</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4895</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4896</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4897</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4898 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      3  4  5  6  7  8  9\n",
       "0     0  0  0  1  0  0  0\n",
       "1     0  0  0  1  0  0  0\n",
       "2     0  0  0  1  0  0  0\n",
       "3     0  0  0  1  0  0  0\n",
       "4     0  0  0  1  0  0  0\n",
       "...  .. .. .. .. .. .. ..\n",
       "4893  0  0  0  1  0  0  0\n",
       "4894  0  0  1  0  0  0  0\n",
       "4895  0  0  0  1  0  0  0\n",
       "4896  0  0  0  0  1  0  0\n",
       "4897  0  0  0  1  0  0  0\n",
       "\n",
       "[4898 rows x 7 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.get_dummies(dataset.quality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-3.48163039e-16,  4.49710592e-16,  1.16054346e-17, -1.06624931e-16,\n",
       "        2.32108693e-17, -1.01547553e-17, -4.64217386e-17,  3.25648496e-14,\n",
       "       -1.18375433e-15, -8.21809840e-16, -3.71373908e-16])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.mean(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, dummy_y, test_size=0.20, \n",
    "                                                    shuffle=True, random_state=47)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3918, 11)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3918, 7)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Keras Sequential ANN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_14 (Dense)             (None, 50)                600       \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 7)                 357       \n",
      "=================================================================\n",
      "Total params: 8,607\n",
      "Trainable params: 8,607\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Sequential Artificial Neural Network Model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "\n",
    "# define your keras model here\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(50, input_dim = X_train.shape[1], activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "model.add(Dense(50, activation='relu'))\n",
    "\n",
    "\n",
    "model.add(Dense(7, activation='softmax'))\n",
    "\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "3918/3918 [==============================] - 0s 119us/step - loss: 1.3380 - accuracy: 0.4666\n",
      "Epoch 2/500\n",
      "3918/3918 [==============================] - 0s 56us/step - loss: 1.1477 - accuracy: 0.5222\n",
      "Epoch 3/500\n",
      "3918/3918 [==============================] - 0s 58us/step - loss: 1.1116 - accuracy: 0.5148\n",
      "Epoch 4/500\n",
      "3918/3918 [==============================] - 0s 57us/step - loss: 1.0841 - accuracy: 0.5332\n",
      "Epoch 5/500\n",
      "3918/3918 [==============================] - 0s 56us/step - loss: 1.0755 - accuracy: 0.5393\n",
      "Epoch 6/500\n",
      "3918/3918 [==============================] - 0s 60us/step - loss: 1.0563 - accuracy: 0.5493\n",
      "Epoch 7/500\n",
      "3918/3918 [==============================] - 0s 61us/step - loss: 1.0528 - accuracy: 0.5518\n",
      "Epoch 8/500\n",
      "3918/3918 [==============================] - 0s 59us/step - loss: 1.0361 - accuracy: 0.5607\n",
      "Epoch 9/500\n",
      "3918/3918 [==============================] - 0s 59us/step - loss: 1.0346 - accuracy: 0.5487\n",
      "Epoch 10/500\n",
      "3918/3918 [==============================] - 0s 55us/step - loss: 1.0294 - accuracy: 0.5615\n",
      "Epoch 11/500\n",
      "3918/3918 [==============================] - 0s 55us/step - loss: 1.0193 - accuracy: 0.5623\n",
      "Epoch 12/500\n",
      "3918/3918 [==============================] - 0s 57us/step - loss: 1.0215 - accuracy: 0.5569\n",
      "Epoch 13/500\n",
      "3918/3918 [==============================] - 0s 56us/step - loss: 1.0067 - accuracy: 0.5630\n",
      "Epoch 14/500\n",
      "3918/3918 [==============================] - 0s 55us/step - loss: 1.0045 - accuracy: 0.5648\n",
      "Epoch 15/500\n",
      "3918/3918 [==============================] - 0s 55us/step - loss: 1.0081 - accuracy: 0.5577\n",
      "Epoch 16/500\n",
      "3918/3918 [==============================] - 0s 55us/step - loss: 0.9921 - accuracy: 0.5679\n",
      "Epoch 17/500\n",
      "3918/3918 [==============================] - 0s 56us/step - loss: 0.9879 - accuracy: 0.5687\n",
      "Epoch 18/500\n",
      "3918/3918 [==============================] - 0s 55us/step - loss: 0.9826 - accuracy: 0.5669\n",
      "Epoch 19/500\n",
      "3918/3918 [==============================] - 0s 54us/step - loss: 0.9852 - accuracy: 0.5628\n",
      "Epoch 20/500\n",
      "3918/3918 [==============================] - 0s 57us/step - loss: 0.9715 - accuracy: 0.5784\n",
      "Epoch 21/500\n",
      "3918/3918 [==============================] - 0s 56us/step - loss: 0.9760 - accuracy: 0.5753\n",
      "Epoch 22/500\n",
      "3918/3918 [==============================] - 0s 53us/step - loss: 0.9653 - accuracy: 0.5778\n",
      "Epoch 23/500\n",
      "3918/3918 [==============================] - 0s 54us/step - loss: 0.9678 - accuracy: 0.5791\n",
      "Epoch 24/500\n",
      "3918/3918 [==============================] - 0s 54us/step - loss: 0.9666 - accuracy: 0.5740\n",
      "Epoch 25/500\n",
      "3918/3918 [==============================] - 0s 55us/step - loss: 0.9578 - accuracy: 0.5881\n",
      "Epoch 26/500\n",
      "3918/3918 [==============================] - 0s 55us/step - loss: 0.9500 - accuracy: 0.5888\n",
      "Epoch 27/500\n",
      "3918/3918 [==============================] - 0s 56us/step - loss: 0.9495 - accuracy: 0.5891\n",
      "Epoch 28/500\n",
      "3918/3918 [==============================] - 0s 57us/step - loss: 0.9438 - accuracy: 0.5906\n",
      "Epoch 29/500\n",
      "3918/3918 [==============================] - 0s 55us/step - loss: 0.9479 - accuracy: 0.5850\n",
      "Epoch 30/500\n",
      "3918/3918 [==============================] - 0s 58us/step - loss: 0.9424 - accuracy: 0.5840\n",
      "Epoch 31/500\n",
      "3918/3918 [==============================] - 0s 56us/step - loss: 0.9357 - accuracy: 0.5878\n",
      "Epoch 32/500\n",
      "3918/3918 [==============================] - 0s 55us/step - loss: 0.9292 - accuracy: 0.5924\n",
      "Epoch 33/500\n",
      "3918/3918 [==============================] - 0s 55us/step - loss: 0.9294 - accuracy: 0.5929\n",
      "Epoch 34/500\n",
      "3918/3918 [==============================] - 0s 58us/step - loss: 0.9129 - accuracy: 0.6036\n",
      "Epoch 35/500\n",
      "3918/3918 [==============================] - 0s 54us/step - loss: 0.9221 - accuracy: 0.5990\n",
      "Epoch 36/500\n",
      "3918/3918 [==============================] - 0s 54us/step - loss: 0.9202 - accuracy: 0.5990\n",
      "Epoch 37/500\n",
      "3918/3918 [==============================] - 0s 55us/step - loss: 0.9150 - accuracy: 0.6044\n",
      "Epoch 38/500\n",
      "3918/3918 [==============================] - 0s 54us/step - loss: 0.9094 - accuracy: 0.6011\n",
      "Epoch 39/500\n",
      "3918/3918 [==============================] - 0s 55us/step - loss: 0.9081 - accuracy: 0.6003\n",
      "Epoch 40/500\n",
      "3918/3918 [==============================] - 0s 56us/step - loss: 0.9146 - accuracy: 0.6049\n",
      "Epoch 41/500\n",
      "3918/3918 [==============================] - 0s 55us/step - loss: 0.8941 - accuracy: 0.6059\n",
      "Epoch 42/500\n",
      "3918/3918 [==============================] - 0s 54us/step - loss: 0.9011 - accuracy: 0.6100\n",
      "Epoch 43/500\n",
      "3918/3918 [==============================] - 0s 54us/step - loss: 0.8994 - accuracy: 0.6046\n",
      "Epoch 44/500\n",
      "3918/3918 [==============================] - 0s 52us/step - loss: 0.8987 - accuracy: 0.6141\n",
      "Epoch 45/500\n",
      "3918/3918 [==============================] - 0s 52us/step - loss: 0.8923 - accuracy: 0.6082\n",
      "Epoch 46/500\n",
      "3918/3918 [==============================] - 0s 53us/step - loss: 0.8775 - accuracy: 0.6161\n",
      "Epoch 47/500\n",
      "3918/3918 [==============================] - 0s 56us/step - loss: 0.8787 - accuracy: 0.6223\n",
      "Epoch 48/500\n",
      "3918/3918 [==============================] - 0s 56us/step - loss: 0.8789 - accuracy: 0.6235\n",
      "Epoch 49/500\n",
      "3918/3918 [==============================] - 0s 56us/step - loss: 0.8841 - accuracy: 0.6177\n",
      "Epoch 50/500\n",
      "3918/3918 [==============================] - 0s 54us/step - loss: 0.8782 - accuracy: 0.6156\n",
      "Epoch 51/500\n",
      "3918/3918 [==============================] - 0s 55us/step - loss: 0.8767 - accuracy: 0.6123\n",
      "Epoch 52/500\n",
      "3918/3918 [==============================] - 0s 57us/step - loss: 0.8788 - accuracy: 0.6194\n",
      "Epoch 53/500\n",
      "3918/3918 [==============================] - 0s 58us/step - loss: 0.8590 - accuracy: 0.6215\n",
      "Epoch 54/500\n",
      "3918/3918 [==============================] - 0s 58us/step - loss: 0.8734 - accuracy: 0.6228\n",
      "Epoch 55/500\n",
      "3918/3918 [==============================] - 0s 57us/step - loss: 0.8706 - accuracy: 0.6235\n",
      "Epoch 56/500\n",
      "3918/3918 [==============================] - 0s 54us/step - loss: 0.8684 - accuracy: 0.6261\n",
      "Epoch 57/500\n",
      "3918/3918 [==============================] - 0s 55us/step - loss: 0.8719 - accuracy: 0.6166\n",
      "Epoch 58/500\n",
      "3918/3918 [==============================] - 0s 54us/step - loss: 0.8585 - accuracy: 0.6223\n",
      "Epoch 59/500\n",
      "3918/3918 [==============================] - 0s 54us/step - loss: 0.8598 - accuracy: 0.6266\n",
      "Epoch 60/500\n",
      "3918/3918 [==============================] - 0s 54us/step - loss: 0.8565 - accuracy: 0.6246\n",
      "Epoch 61/500\n",
      "3918/3918 [==============================] - 0s 55us/step - loss: 0.8543 - accuracy: 0.6299\n",
      "Epoch 62/500\n",
      "3918/3918 [==============================] - 0s 56us/step - loss: 0.8584 - accuracy: 0.6233\n",
      "Epoch 63/500\n",
      "3918/3918 [==============================] - 0s 56us/step - loss: 0.8440 - accuracy: 0.6358\n",
      "Epoch 64/500\n",
      "3918/3918 [==============================] - 0s 54us/step - loss: 0.8320 - accuracy: 0.6434\n",
      "Epoch 65/500\n",
      "3918/3918 [==============================] - 0s 54us/step - loss: 0.8466 - accuracy: 0.6248\n",
      "Epoch 66/500\n",
      "3918/3918 [==============================] - 0s 53us/step - loss: 0.8259 - accuracy: 0.6373\n",
      "Epoch 67/500\n",
      "3918/3918 [==============================] - 0s 54us/step - loss: 0.8406 - accuracy: 0.6386\n",
      "Epoch 68/500\n",
      "3918/3918 [==============================] - 0s 55us/step - loss: 0.8343 - accuracy: 0.6440\n",
      "Epoch 69/500\n",
      "3918/3918 [==============================] - 0s 56us/step - loss: 0.8363 - accuracy: 0.6417\n",
      "Epoch 70/500\n",
      "3918/3918 [==============================] - 0s 54us/step - loss: 0.8303 - accuracy: 0.6404\n",
      "Epoch 71/500\n",
      "3918/3918 [==============================] - 0s 54us/step - loss: 0.8355 - accuracy: 0.6388\n",
      "Epoch 72/500\n",
      "3918/3918 [==============================] - 0s 53us/step - loss: 0.8221 - accuracy: 0.6447\n",
      "Epoch 73/500\n",
      "3918/3918 [==============================] - 0s 54us/step - loss: 0.8278 - accuracy: 0.6450\n",
      "Epoch 74/500\n",
      "3918/3918 [==============================] - 0s 54us/step - loss: 0.8250 - accuracy: 0.6445\n",
      "Epoch 75/500\n",
      "3918/3918 [==============================] - 0s 57us/step - loss: 0.8297 - accuracy: 0.6304\n",
      "Epoch 76/500\n",
      "3918/3918 [==============================] - 0s 56us/step - loss: 0.8170 - accuracy: 0.6422\n",
      "Epoch 77/500\n",
      "3918/3918 [==============================] - 0s 52us/step - loss: 0.8251 - accuracy: 0.6488\n",
      "Epoch 78/500\n",
      "3918/3918 [==============================] - 0s 54us/step - loss: 0.8030 - accuracy: 0.6598\n",
      "Epoch 79/500\n",
      "3918/3918 [==============================] - 0s 53us/step - loss: 0.8258 - accuracy: 0.6442\n",
      "Epoch 80/500\n",
      "3918/3918 [==============================] - 0s 54us/step - loss: 0.8098 - accuracy: 0.6475\n",
      "Epoch 81/500\n",
      "3918/3918 [==============================] - 0s 54us/step - loss: 0.8108 - accuracy: 0.6559\n",
      "Epoch 82/500\n",
      "3918/3918 [==============================] - 0s 54us/step - loss: 0.8182 - accuracy: 0.6508\n",
      "Epoch 83/500\n",
      "3918/3918 [==============================] - 0s 55us/step - loss: 0.7974 - accuracy: 0.6600\n",
      "Epoch 84/500\n",
      "3918/3918 [==============================] - 0s 52us/step - loss: 0.8065 - accuracy: 0.6503\n",
      "Epoch 85/500\n",
      "3918/3918 [==============================] - 0s 55us/step - loss: 0.8051 - accuracy: 0.6519\n",
      "Epoch 86/500\n",
      "3918/3918 [==============================] - 0s 55us/step - loss: 0.8076 - accuracy: 0.6455\n",
      "Epoch 87/500\n",
      "3918/3918 [==============================] - 0s 52us/step - loss: 0.7939 - accuracy: 0.6588\n",
      "Epoch 88/500\n",
      "3918/3918 [==============================] - 0s 52us/step - loss: 0.7960 - accuracy: 0.6588\n",
      "Epoch 89/500\n",
      "3918/3918 [==============================] - 0s 54us/step - loss: 0.8047 - accuracy: 0.6496\n",
      "Epoch 90/500\n",
      "3918/3918 [==============================] - 0s 54us/step - loss: 0.7920 - accuracy: 0.6567\n",
      "Epoch 91/500\n",
      "3918/3918 [==============================] - 0s 51us/step - loss: 0.8012 - accuracy: 0.6636\n",
      "Epoch 92/500\n",
      "3918/3918 [==============================] - 0s 54us/step - loss: 0.7996 - accuracy: 0.6567\n",
      "Epoch 93/500\n",
      "3918/3918 [==============================] - 0s 53us/step - loss: 0.7954 - accuracy: 0.6580\n",
      "Epoch 94/500\n",
      "3918/3918 [==============================] - 0s 54us/step - loss: 0.7928 - accuracy: 0.6539\n",
      "Epoch 95/500\n",
      "3918/3918 [==============================] - 0s 55us/step - loss: 0.7983 - accuracy: 0.6656\n",
      "Epoch 96/500\n",
      "3918/3918 [==============================] - 0s 56us/step - loss: 0.7859 - accuracy: 0.6618\n",
      "Epoch 97/500\n",
      "3918/3918 [==============================] - 0s 56us/step - loss: 0.7834 - accuracy: 0.6590\n",
      "Epoch 98/500\n",
      "3918/3918 [==============================] - 0s 54us/step - loss: 0.7925 - accuracy: 0.6539\n",
      "Epoch 99/500\n",
      "3918/3918 [==============================] - 0s 54us/step - loss: 0.7791 - accuracy: 0.6598\n",
      "Epoch 100/500\n",
      "3918/3918 [==============================] - 0s 52us/step - loss: 0.7845 - accuracy: 0.6577\n",
      "Epoch 101/500\n",
      "3918/3918 [==============================] - 0s 52us/step - loss: 0.7781 - accuracy: 0.6662\n",
      "Epoch 102/500\n",
      "3918/3918 [==============================] - 0s 53us/step - loss: 0.7789 - accuracy: 0.6603\n",
      "Epoch 103/500\n",
      "3918/3918 [==============================] - 0s 56us/step - loss: 0.7812 - accuracy: 0.6649\n",
      "Epoch 104/500\n",
      "3918/3918 [==============================] - 0s 57us/step - loss: 0.7856 - accuracy: 0.6646\n",
      "Epoch 105/500\n",
      "3918/3918 [==============================] - 0s 57us/step - loss: 0.7826 - accuracy: 0.6697\n",
      "Epoch 106/500\n",
      "3918/3918 [==============================] - 0s 55us/step - loss: 0.7753 - accuracy: 0.6753\n",
      "Epoch 107/500\n",
      "3918/3918 [==============================] - 0s 55us/step - loss: 0.7612 - accuracy: 0.6759\n",
      "Epoch 108/500\n",
      "3918/3918 [==============================] - 0s 55us/step - loss: 0.7724 - accuracy: 0.6644\n",
      "Epoch 109/500\n",
      "3918/3918 [==============================] - 0s 57us/step - loss: 0.7691 - accuracy: 0.6713\n",
      "Epoch 110/500\n",
      "3918/3918 [==============================] - 0s 58us/step - loss: 0.7711 - accuracy: 0.6679\n",
      "Epoch 111/500\n",
      "3918/3918 [==============================] - 0s 57us/step - loss: 0.7672 - accuracy: 0.6718\n",
      "Epoch 112/500\n",
      "3918/3918 [==============================] - 0s 56us/step - loss: 0.7586 - accuracy: 0.6674\n",
      "Epoch 113/500\n",
      "3918/3918 [==============================] - 0s 54us/step - loss: 0.7681 - accuracy: 0.6708\n",
      "Epoch 114/500\n",
      "3918/3918 [==============================] - 0s 58us/step - loss: 0.7870 - accuracy: 0.6631\n",
      "Epoch 115/500\n",
      "3918/3918 [==============================] - 0s 58us/step - loss: 0.7663 - accuracy: 0.6708\n",
      "Epoch 116/500\n",
      "3918/3918 [==============================] - 0s 58us/step - loss: 0.7633 - accuracy: 0.6802\n",
      "Epoch 117/500\n",
      "3918/3918 [==============================] - 0s 54us/step - loss: 0.7557 - accuracy: 0.6827\n",
      "Epoch 118/500\n",
      "3918/3918 [==============================] - 0s 57us/step - loss: 0.7701 - accuracy: 0.6695\n",
      "Epoch 119/500\n",
      "3918/3918 [==============================] - 0s 58us/step - loss: 0.7520 - accuracy: 0.6782\n",
      "Epoch 120/500\n",
      "3918/3918 [==============================] - 0s 59us/step - loss: 0.7575 - accuracy: 0.6761\n",
      "Epoch 121/500\n",
      "3918/3918 [==============================] - 0s 62us/step - loss: 0.7532 - accuracy: 0.6840\n",
      "Epoch 122/500\n",
      "3918/3918 [==============================] - 0s 61us/step - loss: 0.7517 - accuracy: 0.6736\n",
      "Epoch 123/500\n",
      "3918/3918 [==============================] - 0s 58us/step - loss: 0.7565 - accuracy: 0.6738\n",
      "Epoch 124/500\n",
      "3918/3918 [==============================] - 0s 59us/step - loss: 0.7499 - accuracy: 0.6708\n",
      "Epoch 125/500\n",
      "3918/3918 [==============================] - 0s 55us/step - loss: 0.7450 - accuracy: 0.6843\n",
      "Epoch 126/500\n",
      "3918/3918 [==============================] - 0s 57us/step - loss: 0.7397 - accuracy: 0.6879\n",
      "Epoch 127/500\n",
      "3918/3918 [==============================] - 0s 56us/step - loss: 0.7412 - accuracy: 0.6840\n",
      "Epoch 128/500\n",
      "3918/3918 [==============================] - 0s 55us/step - loss: 0.7462 - accuracy: 0.6761\n",
      "Epoch 129/500\n",
      "3918/3918 [==============================] - 0s 59us/step - loss: 0.7426 - accuracy: 0.6881\n",
      "Epoch 130/500\n",
      "3918/3918 [==============================] - 0s 59us/step - loss: 0.7449 - accuracy: 0.6830\n",
      "Epoch 131/500\n",
      "3918/3918 [==============================] - 0s 57us/step - loss: 0.7303 - accuracy: 0.6853\n",
      "Epoch 132/500\n",
      "3918/3918 [==============================] - 0s 61us/step - loss: 0.7362 - accuracy: 0.6881\n",
      "Epoch 133/500\n",
      "3918/3918 [==============================] - 0s 58us/step - loss: 0.7396 - accuracy: 0.6840\n",
      "Epoch 134/500\n",
      "3918/3918 [==============================] - 0s 57us/step - loss: 0.7362 - accuracy: 0.6856\n",
      "Epoch 135/500\n",
      "3918/3918 [==============================] - 0s 56us/step - loss: 0.7303 - accuracy: 0.6963\n",
      "Epoch 136/500\n",
      "3918/3918 [==============================] - 0s 56us/step - loss: 0.7414 - accuracy: 0.6779\n",
      "Epoch 137/500\n",
      "3918/3918 [==============================] - 0s 59us/step - loss: 0.7465 - accuracy: 0.6822\n",
      "Epoch 138/500\n",
      "3918/3918 [==============================] - 0s 56us/step - loss: 0.7357 - accuracy: 0.6815 0s - loss: 0.7316 - accuracy\n",
      "Epoch 139/500\n",
      "3918/3918 [==============================] - 0s 60us/step - loss: 0.7356 - accuracy: 0.6804\n",
      "Epoch 140/500\n",
      "3918/3918 [==============================] - 0s 60us/step - loss: 0.7362 - accuracy: 0.6833\n",
      "Epoch 141/500\n",
      "3918/3918 [==============================] - 0s 58us/step - loss: 0.7323 - accuracy: 0.6891\n",
      "Epoch 142/500\n",
      "3918/3918 [==============================] - 0s 58us/step - loss: 0.7288 - accuracy: 0.6917\n",
      "Epoch 143/500\n",
      "3918/3918 [==============================] - 0s 59us/step - loss: 0.7095 - accuracy: 0.6965\n",
      "Epoch 144/500\n",
      "3918/3918 [==============================] - 0s 61us/step - loss: 0.7200 - accuracy: 0.6894\n",
      "Epoch 145/500\n",
      "3918/3918 [==============================] - 0s 58us/step - loss: 0.7298 - accuracy: 0.6822\n",
      "Epoch 146/500\n",
      "3918/3918 [==============================] - 0s 58us/step - loss: 0.7353 - accuracy: 0.6792\n",
      "Epoch 147/500\n",
      "3918/3918 [==============================] - 0s 56us/step - loss: 0.7221 - accuracy: 0.6963\n",
      "Epoch 148/500\n",
      "3918/3918 [==============================] - 0s 59us/step - loss: 0.7209 - accuracy: 0.6863\n",
      "Epoch 149/500\n",
      "3918/3918 [==============================] - 0s 57us/step - loss: 0.7222 - accuracy: 0.6904\n",
      "Epoch 150/500\n",
      "3918/3918 [==============================] - 0s 57us/step - loss: 0.7291 - accuracy: 0.6917\n",
      "Epoch 151/500\n",
      "3918/3918 [==============================] - 0s 58us/step - loss: 0.7317 - accuracy: 0.6843\n",
      "Epoch 152/500\n",
      "3918/3918 [==============================] - 0s 61us/step - loss: 0.7157 - accuracy: 0.6922\n",
      "Epoch 153/500\n",
      "3918/3918 [==============================] - 0s 58us/step - loss: 0.7225 - accuracy: 0.6947\n",
      "Epoch 154/500\n",
      "3918/3918 [==============================] - 0s 63us/step - loss: 0.7244 - accuracy: 0.6886\n",
      "Epoch 155/500\n",
      "3918/3918 [==============================] - 0s 60us/step - loss: 0.7215 - accuracy: 0.6901\n",
      "Epoch 156/500\n",
      "3918/3918 [==============================] - 0s 58us/step - loss: 0.7245 - accuracy: 0.6942\n",
      "Epoch 157/500\n",
      "3918/3918 [==============================] - 0s 52us/step - loss: 0.7165 - accuracy: 0.6955\n",
      "Epoch 158/500\n",
      "3918/3918 [==============================] - 0s 53us/step - loss: 0.7080 - accuracy: 0.7011\n",
      "Epoch 159/500\n",
      "3918/3918 [==============================] - 0s 55us/step - loss: 0.7159 - accuracy: 0.6983\n",
      "Epoch 160/500\n",
      "3918/3918 [==============================] - 0s 52us/step - loss: 0.7179 - accuracy: 0.6904\n",
      "Epoch 161/500\n",
      "3918/3918 [==============================] - 0s 54us/step - loss: 0.7232 - accuracy: 0.6896\n",
      "Epoch 162/500\n",
      "3918/3918 [==============================] - 0s 55us/step - loss: 0.7166 - accuracy: 0.6981\n",
      "Epoch 163/500\n",
      "3918/3918 [==============================] - 0s 54us/step - loss: 0.7203 - accuracy: 0.6919\n",
      "Epoch 164/500\n",
      "3918/3918 [==============================] - 0s 52us/step - loss: 0.7180 - accuracy: 0.6970\n",
      "Epoch 165/500\n",
      "3918/3918 [==============================] - 0s 56us/step - loss: 0.6990 - accuracy: 0.7037\n",
      "Epoch 166/500\n",
      "3918/3918 [==============================] - 0s 54us/step - loss: 0.7184 - accuracy: 0.7029\n",
      "Epoch 167/500\n",
      "3918/3918 [==============================] - 0s 53us/step - loss: 0.7093 - accuracy: 0.7024\n",
      "Epoch 168/500\n",
      "3918/3918 [==============================] - 0s 54us/step - loss: 0.7143 - accuracy: 0.6950\n",
      "Epoch 169/500\n",
      "3918/3918 [==============================] - 0s 54us/step - loss: 0.7265 - accuracy: 0.6970\n",
      "Epoch 170/500\n",
      "3918/3918 [==============================] - 0s 55us/step - loss: 0.7113 - accuracy: 0.7042\n",
      "Epoch 171/500\n",
      "3918/3918 [==============================] - 0s 56us/step - loss: 0.7040 - accuracy: 0.7001\n",
      "Epoch 172/500\n",
      "3918/3918 [==============================] - 0s 52us/step - loss: 0.6900 - accuracy: 0.7093\n",
      "Epoch 173/500\n",
      "3918/3918 [==============================] - 0s 51us/step - loss: 0.7217 - accuracy: 0.6863\n",
      "Epoch 174/500\n",
      "3918/3918 [==============================] - 0s 55us/step - loss: 0.7050 - accuracy: 0.6978\n",
      "Epoch 175/500\n",
      "3918/3918 [==============================] - 0s 56us/step - loss: 0.6963 - accuracy: 0.6996\n",
      "Epoch 176/500\n",
      "3918/3918 [==============================] - 0s 57us/step - loss: 0.7086 - accuracy: 0.7062\n",
      "Epoch 177/500\n",
      "3918/3918 [==============================] - 0s 59us/step - loss: 0.7043 - accuracy: 0.7065\n",
      "Epoch 178/500\n",
      "3918/3918 [==============================] - 0s 55us/step - loss: 0.7080 - accuracy: 0.6986\n",
      "Epoch 179/500\n",
      "3918/3918 [==============================] - 0s 56us/step - loss: 0.7109 - accuracy: 0.7106\n",
      "Epoch 180/500\n",
      "3918/3918 [==============================] - 0s 55us/step - loss: 0.7191 - accuracy: 0.6970\n",
      "Epoch 181/500\n",
      "3918/3918 [==============================] - 0s 53us/step - loss: 0.6856 - accuracy: 0.7111\n",
      "Epoch 182/500\n",
      "3918/3918 [==============================] - 0s 54us/step - loss: 0.7096 - accuracy: 0.6973\n",
      "Epoch 183/500\n",
      "3918/3918 [==============================] - 0s 56us/step - loss: 0.7029 - accuracy: 0.7042\n",
      "Epoch 184/500\n",
      "3918/3918 [==============================] - 0s 55us/step - loss: 0.7075 - accuracy: 0.7047\n",
      "Epoch 185/500\n",
      "3918/3918 [==============================] - 0s 58us/step - loss: 0.7019 - accuracy: 0.7108\n",
      "Epoch 186/500\n",
      "3918/3918 [==============================] - 0s 58us/step - loss: 0.6898 - accuracy: 0.7009\n",
      "Epoch 187/500\n",
      "3918/3918 [==============================] - 0s 61us/step - loss: 0.6941 - accuracy: 0.7032\n",
      "Epoch 188/500\n",
      "3918/3918 [==============================] - 0s 59us/step - loss: 0.6920 - accuracy: 0.7034\n",
      "Epoch 189/500\n",
      "3918/3918 [==============================] - 0s 57us/step - loss: 0.6828 - accuracy: 0.7116\n",
      "Epoch 190/500\n",
      "3918/3918 [==============================] - 0s 55us/step - loss: 0.6838 - accuracy: 0.7149\n",
      "Epoch 191/500\n",
      "3918/3918 [==============================] - 0s 55us/step - loss: 0.6885 - accuracy: 0.7085\n",
      "Epoch 192/500\n",
      "3918/3918 [==============================] - 0s 55us/step - loss: 0.6939 - accuracy: 0.7162\n",
      "Epoch 193/500\n",
      "3918/3918 [==============================] - 0s 55us/step - loss: 0.6945 - accuracy: 0.7126\n",
      "Epoch 194/500\n",
      "3918/3918 [==============================] - 0s 56us/step - loss: 0.6940 - accuracy: 0.7129\n",
      "Epoch 195/500\n",
      "3918/3918 [==============================] - 0s 54us/step - loss: 0.6956 - accuracy: 0.7001\n",
      "Epoch 196/500\n",
      "3918/3918 [==============================] - 0s 57us/step - loss: 0.6935 - accuracy: 0.7095\n",
      "Epoch 197/500\n",
      "3918/3918 [==============================] - 0s 56us/step - loss: 0.6854 - accuracy: 0.7134\n",
      "Epoch 198/500\n",
      "3918/3918 [==============================] - 0s 56us/step - loss: 0.6842 - accuracy: 0.7103\n",
      "Epoch 199/500\n",
      "3918/3918 [==============================] - 0s 57us/step - loss: 0.6940 - accuracy: 0.7080\n",
      "Epoch 200/500\n",
      "3918/3918 [==============================] - 0s 57us/step - loss: 0.6838 - accuracy: 0.7149\n",
      "Epoch 201/500\n",
      "3918/3918 [==============================] - 0s 57us/step - loss: 0.7093 - accuracy: 0.7032\n",
      "Epoch 202/500\n",
      "3918/3918 [==============================] - 0s 57us/step - loss: 0.6921 - accuracy: 0.7118\n",
      "Epoch 203/500\n",
      "3918/3918 [==============================] - 0s 56us/step - loss: 0.6996 - accuracy: 0.7042\n",
      "Epoch 204/500\n",
      "3918/3918 [==============================] - 0s 55us/step - loss: 0.7097 - accuracy: 0.7004\n",
      "Epoch 205/500\n",
      "3918/3918 [==============================] - 0s 54us/step - loss: 0.6596 - accuracy: 0.7205\n",
      "Epoch 206/500\n",
      "3918/3918 [==============================] - 0s 55us/step - loss: 0.6822 - accuracy: 0.7057\n",
      "Epoch 207/500\n",
      "3918/3918 [==============================] - 0s 54us/step - loss: 0.6863 - accuracy: 0.7169\n",
      "Epoch 208/500\n",
      "3918/3918 [==============================] - 0s 59us/step - loss: 0.6886 - accuracy: 0.7149\n",
      "Epoch 209/500\n",
      "3918/3918 [==============================] - 0s 63us/step - loss: 0.6734 - accuracy: 0.7139\n",
      "Epoch 210/500\n",
      "3918/3918 [==============================] - 0s 62us/step - loss: 0.6785 - accuracy: 0.7129\n",
      "Epoch 211/500\n",
      "3918/3918 [==============================] - 0s 57us/step - loss: 0.6730 - accuracy: 0.7182\n",
      "Epoch 212/500\n",
      "3918/3918 [==============================] - 0s 56us/step - loss: 0.6919 - accuracy: 0.7152\n",
      "Epoch 213/500\n",
      "3918/3918 [==============================] - 0s 54us/step - loss: 0.6760 - accuracy: 0.7055\n",
      "Epoch 214/500\n",
      "3918/3918 [==============================] - 0s 56us/step - loss: 0.6722 - accuracy: 0.7254\n",
      "Epoch 215/500\n",
      "3918/3918 [==============================] - 0s 55us/step - loss: 0.6910 - accuracy: 0.7070\n",
      "Epoch 216/500\n",
      "3918/3918 [==============================] - 0s 56us/step - loss: 0.6752 - accuracy: 0.7141\n",
      "Epoch 217/500\n",
      "3918/3918 [==============================] - 0s 55us/step - loss: 0.6749 - accuracy: 0.7182\n",
      "Epoch 218/500\n",
      "3918/3918 [==============================] - 0s 57us/step - loss: 0.6794 - accuracy: 0.7164\n",
      "Epoch 219/500\n",
      "3918/3918 [==============================] - 0s 61us/step - loss: 0.6857 - accuracy: 0.7147\n",
      "Epoch 220/500\n",
      "3918/3918 [==============================] - 0s 61us/step - loss: 0.6819 - accuracy: 0.7238\n",
      "Epoch 221/500\n",
      "3918/3918 [==============================] - 0s 58us/step - loss: 0.6709 - accuracy: 0.7208\n",
      "Epoch 222/500\n",
      "3918/3918 [==============================] - 0s 59us/step - loss: 0.6916 - accuracy: 0.7121\n",
      "Epoch 223/500\n",
      "3918/3918 [==============================] - 0s 58us/step - loss: 0.6775 - accuracy: 0.7213\n",
      "Epoch 224/500\n",
      "3918/3918 [==============================] - 0s 57us/step - loss: 0.6727 - accuracy: 0.7264\n",
      "Epoch 225/500\n",
      "3918/3918 [==============================] - 0s 54us/step - loss: 0.6655 - accuracy: 0.7266\n",
      "Epoch 226/500\n",
      "3918/3918 [==============================] - 0s 53us/step - loss: 0.6865 - accuracy: 0.7126\n",
      "Epoch 227/500\n",
      "3918/3918 [==============================] - 0s 53us/step - loss: 0.6827 - accuracy: 0.7141\n",
      "Epoch 228/500\n",
      "3918/3918 [==============================] - 0s 56us/step - loss: 0.6790 - accuracy: 0.7185\n",
      "Epoch 229/500\n",
      "3918/3918 [==============================] - 0s 56us/step - loss: 0.6838 - accuracy: 0.7111\n",
      "Epoch 230/500\n",
      "3918/3918 [==============================] - 0s 60us/step - loss: 0.6791 - accuracy: 0.7175\n",
      "Epoch 231/500\n",
      "3918/3918 [==============================] - 0s 57us/step - loss: 0.6529 - accuracy: 0.7356\n",
      "Epoch 232/500\n",
      "3918/3918 [==============================] - 0s 57us/step - loss: 0.6813 - accuracy: 0.7124\n",
      "Epoch 233/500\n",
      "3918/3918 [==============================] - 0s 58us/step - loss: 0.6848 - accuracy: 0.7060\n",
      "Epoch 234/500\n",
      "3918/3918 [==============================] - 0s 58us/step - loss: 0.6681 - accuracy: 0.7246\n",
      "Epoch 235/500\n",
      "3918/3918 [==============================] - 0s 55us/step - loss: 0.6758 - accuracy: 0.7106\n",
      "Epoch 236/500\n",
      "3918/3918 [==============================] - 0s 58us/step - loss: 0.6541 - accuracy: 0.7215\n",
      "Epoch 237/500\n",
      "3918/3918 [==============================] - 0s 63us/step - loss: 0.6758 - accuracy: 0.7139\n",
      "Epoch 238/500\n",
      "3918/3918 [==============================] - 0s 56us/step - loss: 0.6626 - accuracy: 0.7277\n",
      "Epoch 239/500\n",
      "3918/3918 [==============================] - 0s 52us/step - loss: 0.6620 - accuracy: 0.7200\n",
      "Epoch 240/500\n",
      "3918/3918 [==============================] - 0s 55us/step - loss: 0.6420 - accuracy: 0.7315\n",
      "Epoch 241/500\n",
      "3918/3918 [==============================] - 0s 56us/step - loss: 0.6678 - accuracy: 0.7149\n",
      "Epoch 242/500\n",
      "3918/3918 [==============================] - 0s 57us/step - loss: 0.6670 - accuracy: 0.7095\n",
      "Epoch 243/500\n",
      "3918/3918 [==============================] - 0s 58us/step - loss: 0.6881 - accuracy: 0.7134\n",
      "Epoch 244/500\n",
      "3918/3918 [==============================] - 0s 58us/step - loss: 0.6757 - accuracy: 0.7200\n",
      "Epoch 245/500\n",
      "3918/3918 [==============================] - 0s 58us/step - loss: 0.6521 - accuracy: 0.7297\n",
      "Epoch 246/500\n",
      "3918/3918 [==============================] - 0s 54us/step - loss: 0.6527 - accuracy: 0.7208\n",
      "Epoch 247/500\n",
      "3918/3918 [==============================] - 0s 53us/step - loss: 0.6563 - accuracy: 0.7289\n",
      "Epoch 248/500\n",
      "3918/3918 [==============================] - 0s 53us/step - loss: 0.6769 - accuracy: 0.7203\n",
      "Epoch 249/500\n",
      "3918/3918 [==============================] - 0s 56us/step - loss: 0.6632 - accuracy: 0.7254\n",
      "Epoch 250/500\n",
      "3918/3918 [==============================] - 0s 56us/step - loss: 0.6502 - accuracy: 0.7312\n",
      "Epoch 251/500\n",
      "3918/3918 [==============================] - 0s 56us/step - loss: 0.6602 - accuracy: 0.7172\n",
      "Epoch 252/500\n",
      "3918/3918 [==============================] - 0s 56us/step - loss: 0.6596 - accuracy: 0.7215\n",
      "Epoch 253/500\n",
      "3918/3918 [==============================] - 0s 57us/step - loss: 0.6769 - accuracy: 0.7185\n",
      "Epoch 254/500\n",
      "3918/3918 [==============================] - 0s 55us/step - loss: 0.6701 - accuracy: 0.7241\n",
      "Epoch 255/500\n",
      "3918/3918 [==============================] - 0s 55us/step - loss: 0.6633 - accuracy: 0.7269\n",
      "Epoch 256/500\n",
      "3918/3918 [==============================] - 0s 57us/step - loss: 0.6555 - accuracy: 0.7185\n",
      "Epoch 257/500\n",
      "3918/3918 [==============================] - 0s 58us/step - loss: 0.6740 - accuracy: 0.7152\n",
      "Epoch 258/500\n",
      "3918/3918 [==============================] - 0s 57us/step - loss: 0.6537 - accuracy: 0.7312\n",
      "Epoch 259/500\n",
      "3918/3918 [==============================] - 0s 55us/step - loss: 0.6536 - accuracy: 0.7343\n",
      "Epoch 260/500\n",
      "3918/3918 [==============================] - 0s 55us/step - loss: 0.6484 - accuracy: 0.7231\n",
      "Epoch 261/500\n",
      "3918/3918 [==============================] - 0s 54us/step - loss: 0.6562 - accuracy: 0.7241\n",
      "Epoch 262/500\n",
      "3918/3918 [==============================] - 0s 56us/step - loss: 0.6586 - accuracy: 0.7215\n",
      "Epoch 263/500\n",
      "3918/3918 [==============================] - 0s 57us/step - loss: 0.6483 - accuracy: 0.7315\n",
      "Epoch 264/500\n",
      "3918/3918 [==============================] - 0s 56us/step - loss: 0.6562 - accuracy: 0.7320\n",
      "Epoch 265/500\n",
      "3918/3918 [==============================] - 0s 54us/step - loss: 0.6674 - accuracy: 0.7269\n",
      "Epoch 266/500\n",
      "3918/3918 [==============================] - 0s 54us/step - loss: 0.6708 - accuracy: 0.7328\n",
      "Epoch 267/500\n",
      "3918/3918 [==============================] - 0s 56us/step - loss: 0.6449 - accuracy: 0.7292\n",
      "Epoch 268/500\n",
      "3918/3918 [==============================] - 0s 55us/step - loss: 0.6596 - accuracy: 0.7274\n",
      "Epoch 269/500\n",
      "3918/3918 [==============================] - 0s 56us/step - loss: 0.6704 - accuracy: 0.7266\n",
      "Epoch 270/500\n",
      "3918/3918 [==============================] - 0s 57us/step - loss: 0.6502 - accuracy: 0.7266\n",
      "Epoch 271/500\n",
      "3918/3918 [==============================] - 0s 56us/step - loss: 0.6537 - accuracy: 0.7264\n",
      "Epoch 272/500\n",
      "3918/3918 [==============================] - 0s 54us/step - loss: 0.6323 - accuracy: 0.7330\n",
      "Epoch 273/500\n",
      "3918/3918 [==============================] - 0s 55us/step - loss: 0.6438 - accuracy: 0.7300\n",
      "Epoch 274/500\n",
      "3918/3918 [==============================] - 0s 55us/step - loss: 0.6556 - accuracy: 0.7177\n",
      "Epoch 275/500\n",
      "3918/3918 [==============================] - 0s 52us/step - loss: 0.6499 - accuracy: 0.7297\n",
      "Epoch 276/500\n",
      "3918/3918 [==============================] - 0s 55us/step - loss: 0.6482 - accuracy: 0.7272\n",
      "Epoch 277/500\n",
      "3918/3918 [==============================] - 0s 56us/step - loss: 0.6251 - accuracy: 0.7443\n",
      "Epoch 278/500\n",
      "3918/3918 [==============================] - 0s 58us/step - loss: 0.6469 - accuracy: 0.7328\n",
      "Epoch 279/500\n",
      "3918/3918 [==============================] - 0s 57us/step - loss: 0.6553 - accuracy: 0.7231\n",
      "Epoch 280/500\n",
      "3918/3918 [==============================] - 0s 57us/step - loss: 0.6519 - accuracy: 0.7305\n",
      "Epoch 281/500\n",
      "3918/3918 [==============================] - 0s 57us/step - loss: 0.6532 - accuracy: 0.7302\n",
      "Epoch 282/500\n",
      "3918/3918 [==============================] - 0s 57us/step - loss: 0.6597 - accuracy: 0.7305\n",
      "Epoch 283/500\n",
      "3918/3918 [==============================] - 0s 58us/step - loss: 0.6476 - accuracy: 0.7330\n",
      "Epoch 284/500\n",
      "3918/3918 [==============================] - 0s 57us/step - loss: 0.6529 - accuracy: 0.7340\n",
      "Epoch 285/500\n",
      "3918/3918 [==============================] - 0s 56us/step - loss: 0.6624 - accuracy: 0.7251\n",
      "Epoch 286/500\n",
      "3918/3918 [==============================] - 0s 56us/step - loss: 0.6328 - accuracy: 0.7346\n",
      "Epoch 287/500\n",
      "3918/3918 [==============================] - 0s 55us/step - loss: 0.6453 - accuracy: 0.7333\n",
      "Epoch 288/500\n",
      "3918/3918 [==============================] - 0s 54us/step - loss: 0.6347 - accuracy: 0.7366\n",
      "Epoch 289/500\n",
      "3918/3918 [==============================] - 0s 54us/step - loss: 0.6553 - accuracy: 0.7310\n",
      "Epoch 290/500\n",
      "3918/3918 [==============================] - 0s 56us/step - loss: 0.6611 - accuracy: 0.7213\n",
      "Epoch 291/500\n",
      "3918/3918 [==============================] - 0s 55us/step - loss: 0.6255 - accuracy: 0.7437\n",
      "Epoch 292/500\n",
      "3918/3918 [==============================] - 0s 53us/step - loss: 0.6471 - accuracy: 0.7243\n",
      "Epoch 293/500\n",
      "3918/3918 [==============================] - 0s 54us/step - loss: 0.6342 - accuracy: 0.7376\n",
      "Epoch 294/500\n",
      "3918/3918 [==============================] - 0s 57us/step - loss: 0.6443 - accuracy: 0.7328\n",
      "Epoch 295/500\n",
      "3918/3918 [==============================] - 0s 56us/step - loss: 0.6389 - accuracy: 0.7435\n",
      "Epoch 296/500\n",
      "3918/3918 [==============================] - 0s 57us/step - loss: 0.6368 - accuracy: 0.7412\n",
      "Epoch 297/500\n",
      "3918/3918 [==============================] - 0s 56us/step - loss: 0.6424 - accuracy: 0.7397\n",
      "Epoch 298/500\n",
      "3918/3918 [==============================] - 0s 58us/step - loss: 0.6459 - accuracy: 0.7358\n",
      "Epoch 299/500\n",
      "3918/3918 [==============================] - 0s 56us/step - loss: 0.6615 - accuracy: 0.7238\n",
      "Epoch 300/500\n",
      "3918/3918 [==============================] - 0s 56us/step - loss: 0.6565 - accuracy: 0.7320\n",
      "Epoch 301/500\n",
      "3918/3918 [==============================] - 0s 58us/step - loss: 0.6472 - accuracy: 0.7289\n",
      "Epoch 302/500\n",
      "3918/3918 [==============================] - 0s 57us/step - loss: 0.6389 - accuracy: 0.7351\n",
      "Epoch 303/500\n",
      "3918/3918 [==============================] - 0s 57us/step - loss: 0.6515 - accuracy: 0.7228\n",
      "Epoch 304/500\n",
      "3918/3918 [==============================] - 0s 58us/step - loss: 0.6422 - accuracy: 0.7361\n",
      "Epoch 305/500\n",
      "3918/3918 [==============================] - 0s 57us/step - loss: 0.6463 - accuracy: 0.7379\n",
      "Epoch 306/500\n",
      "3918/3918 [==============================] - 0s 55us/step - loss: 0.6432 - accuracy: 0.7228\n",
      "Epoch 307/500\n",
      "3918/3918 [==============================] - 0s 57us/step - loss: 0.6514 - accuracy: 0.7272\n",
      "Epoch 308/500\n",
      "3918/3918 [==============================] - 0s 54us/step - loss: 0.6391 - accuracy: 0.7376\n",
      "Epoch 309/500\n",
      "3918/3918 [==============================] - 0s 56us/step - loss: 0.6366 - accuracy: 0.7356\n",
      "Epoch 310/500\n",
      "3918/3918 [==============================] - 0s 57us/step - loss: 0.6300 - accuracy: 0.7486\n",
      "Epoch 311/500\n",
      "3918/3918 [==============================] - 0s 58us/step - loss: 0.6336 - accuracy: 0.7404\n",
      "Epoch 312/500\n",
      "3918/3918 [==============================] - 0s 56us/step - loss: 0.6270 - accuracy: 0.7501\n",
      "Epoch 313/500\n",
      "3918/3918 [==============================] - 0s 56us/step - loss: 0.6270 - accuracy: 0.7437\n",
      "Epoch 314/500\n",
      "3918/3918 [==============================] - 0s 55us/step - loss: 0.6405 - accuracy: 0.7269\n",
      "Epoch 315/500\n",
      "3918/3918 [==============================] - 0s 55us/step - loss: 0.6423 - accuracy: 0.7384\n",
      "Epoch 316/500\n",
      "3918/3918 [==============================] - 0s 57us/step - loss: 0.6259 - accuracy: 0.7476\n",
      "Epoch 317/500\n",
      "3918/3918 [==============================] - 0s 59us/step - loss: 0.6342 - accuracy: 0.7371\n",
      "Epoch 318/500\n",
      "3918/3918 [==============================] - 0s 57us/step - loss: 0.6325 - accuracy: 0.7445\n",
      "Epoch 319/500\n",
      "3918/3918 [==============================] - 0s 57us/step - loss: 0.6318 - accuracy: 0.7366\n",
      "Epoch 320/500\n",
      "3918/3918 [==============================] - 0s 57us/step - loss: 0.6530 - accuracy: 0.7312\n",
      "Epoch 321/500\n",
      "3918/3918 [==============================] - 0s 56us/step - loss: 0.6469 - accuracy: 0.7307\n",
      "Epoch 322/500\n",
      "3918/3918 [==============================] - 0s 58us/step - loss: 0.6255 - accuracy: 0.7453\n",
      "Epoch 323/500\n",
      "3918/3918 [==============================] - 0s 58us/step - loss: 0.6439 - accuracy: 0.7295\n",
      "Epoch 324/500\n",
      "3918/3918 [==============================] - 0s 58us/step - loss: 0.6397 - accuracy: 0.7386\n",
      "Epoch 325/500\n",
      "3918/3918 [==============================] - 0s 56us/step - loss: 0.6096 - accuracy: 0.7463\n",
      "Epoch 326/500\n",
      "3918/3918 [==============================] - 0s 56us/step - loss: 0.6348 - accuracy: 0.7409\n",
      "Epoch 327/500\n",
      "3918/3918 [==============================] - 0s 55us/step - loss: 0.6177 - accuracy: 0.7414\n",
      "Epoch 328/500\n",
      "3918/3918 [==============================] - 0s 55us/step - loss: 0.6423 - accuracy: 0.7295\n",
      "Epoch 329/500\n",
      "3918/3918 [==============================] - 0s 57us/step - loss: 0.6160 - accuracy: 0.7460\n",
      "Epoch 330/500\n",
      "3918/3918 [==============================] - 0s 62us/step - loss: 0.6274 - accuracy: 0.7369\n",
      "Epoch 331/500\n",
      "3918/3918 [==============================] - 0s 60us/step - loss: 0.6346 - accuracy: 0.7348\n",
      "Epoch 332/500\n",
      "3918/3918 [==============================] - 0s 55us/step - loss: 0.6416 - accuracy: 0.7351\n",
      "Epoch 333/500\n",
      "3918/3918 [==============================] - 0s 57us/step - loss: 0.6437 - accuracy: 0.7323\n",
      "Epoch 334/500\n",
      "3918/3918 [==============================] - 0s 57us/step - loss: 0.6081 - accuracy: 0.7471\n",
      "Epoch 335/500\n",
      "3918/3918 [==============================] - 0s 57us/step - loss: 0.6323 - accuracy: 0.7430 0s - loss: 0.6130 - accuracy: 0.\n",
      "Epoch 336/500\n",
      "3918/3918 [==============================] - 0s 64us/step - loss: 0.6260 - accuracy: 0.7463\n",
      "Epoch 337/500\n",
      "3918/3918 [==============================] - 0s 61us/step - loss: 0.6397 - accuracy: 0.7381\n",
      "Epoch 338/500\n",
      "3918/3918 [==============================] - 0s 56us/step - loss: 0.6315 - accuracy: 0.7379\n",
      "Epoch 339/500\n",
      "3918/3918 [==============================] - 0s 56us/step - loss: 0.6226 - accuracy: 0.7537\n",
      "Epoch 340/500\n",
      "3918/3918 [==============================] - 0s 58us/step - loss: 0.6324 - accuracy: 0.7381\n",
      "Epoch 341/500\n",
      "3918/3918 [==============================] - 0s 59us/step - loss: 0.6319 - accuracy: 0.7427\n",
      "Epoch 342/500\n",
      "3918/3918 [==============================] - 0s 60us/step - loss: 0.6429 - accuracy: 0.7414\n",
      "Epoch 343/500\n",
      "3918/3918 [==============================] - 0s 62us/step - loss: 0.6348 - accuracy: 0.7374\n",
      "Epoch 344/500\n",
      "3918/3918 [==============================] - 0s 60us/step - loss: 0.6508 - accuracy: 0.7435\n",
      "Epoch 345/500\n",
      "3918/3918 [==============================] - 0s 58us/step - loss: 0.6245 - accuracy: 0.7443\n",
      "Epoch 346/500\n",
      "3918/3918 [==============================] - 0s 59us/step - loss: 0.6362 - accuracy: 0.7325\n",
      "Epoch 347/500\n",
      "3918/3918 [==============================] - 0s 59us/step - loss: 0.6230 - accuracy: 0.7481\n",
      "Epoch 348/500\n",
      "3918/3918 [==============================] - 0s 58us/step - loss: 0.6082 - accuracy: 0.7473\n",
      "Epoch 349/500\n",
      "3918/3918 [==============================] - 0s 59us/step - loss: 0.6207 - accuracy: 0.7468\n",
      "Epoch 350/500\n",
      "3918/3918 [==============================] - 0s 58us/step - loss: 0.6552 - accuracy: 0.7297\n",
      "Epoch 351/500\n",
      "3918/3918 [==============================] - 0s 59us/step - loss: 0.6143 - accuracy: 0.7414\n",
      "Epoch 352/500\n",
      "3918/3918 [==============================] - 0s 61us/step - loss: 0.6387 - accuracy: 0.7499\n",
      "Epoch 353/500\n",
      "3918/3918 [==============================] - 0s 58us/step - loss: 0.6314 - accuracy: 0.7356\n",
      "Epoch 354/500\n",
      "3918/3918 [==============================] - 0s 59us/step - loss: 0.6262 - accuracy: 0.7381\n",
      "Epoch 355/500\n",
      "3918/3918 [==============================] - 0s 69us/step - loss: 0.6125 - accuracy: 0.7560\n",
      "Epoch 356/500\n",
      "3918/3918 [==============================] - 0s 70us/step - loss: 0.6316 - accuracy: 0.7356\n",
      "Epoch 357/500\n",
      "3918/3918 [==============================] - 0s 66us/step - loss: 0.6317 - accuracy: 0.7381\n",
      "Epoch 358/500\n",
      "3918/3918 [==============================] - 0s 60us/step - loss: 0.6333 - accuracy: 0.7409\n",
      "Epoch 359/500\n",
      "3918/3918 [==============================] - 0s 58us/step - loss: 0.6449 - accuracy: 0.7346\n",
      "Epoch 360/500\n",
      "3918/3918 [==============================] - 0s 64us/step - loss: 0.6332 - accuracy: 0.7437\n",
      "Epoch 361/500\n",
      "3918/3918 [==============================] - 0s 68us/step - loss: 0.6116 - accuracy: 0.7499\n",
      "Epoch 362/500\n",
      "3918/3918 [==============================] - 0s 63us/step - loss: 0.6424 - accuracy: 0.7374\n",
      "Epoch 363/500\n",
      "3918/3918 [==============================] - 0s 70us/step - loss: 0.6487 - accuracy: 0.7407\n",
      "Epoch 364/500\n",
      "3918/3918 [==============================] - 0s 65us/step - loss: 0.6588 - accuracy: 0.7277\n",
      "Epoch 365/500\n",
      "3918/3918 [==============================] - 0s 60us/step - loss: 0.6248 - accuracy: 0.7425\n",
      "Epoch 366/500\n",
      "3918/3918 [==============================] - 0s 60us/step - loss: 0.6110 - accuracy: 0.7565\n",
      "Epoch 367/500\n",
      "3918/3918 [==============================] - 0s 61us/step - loss: 0.6078 - accuracy: 0.7506\n",
      "Epoch 368/500\n",
      "3918/3918 [==============================] - 0s 62us/step - loss: 0.6247 - accuracy: 0.7443\n",
      "Epoch 369/500\n",
      "3918/3918 [==============================] - 0s 62us/step - loss: 0.6224 - accuracy: 0.7414\n",
      "Epoch 370/500\n",
      "3918/3918 [==============================] - 0s 61us/step - loss: 0.6128 - accuracy: 0.7563\n",
      "Epoch 371/500\n",
      "3918/3918 [==============================] - 0s 60us/step - loss: 0.6356 - accuracy: 0.7394\n",
      "Epoch 372/500\n",
      "3918/3918 [==============================] - 0s 62us/step - loss: 0.6252 - accuracy: 0.7471\n",
      "Epoch 373/500\n",
      "3918/3918 [==============================] - 0s 62us/step - loss: 0.6034 - accuracy: 0.7494\n",
      "Epoch 374/500\n",
      "3918/3918 [==============================] - 0s 64us/step - loss: 0.6263 - accuracy: 0.7453\n",
      "Epoch 375/500\n",
      "3918/3918 [==============================] - 0s 66us/step - loss: 0.6120 - accuracy: 0.7529\n",
      "Epoch 376/500\n",
      "3918/3918 [==============================] - 0s 63us/step - loss: 0.6297 - accuracy: 0.7335\n",
      "Epoch 377/500\n",
      "3918/3918 [==============================] - 0s 59us/step - loss: 0.6191 - accuracy: 0.7445\n",
      "Epoch 378/500\n",
      "3918/3918 [==============================] - 0s 56us/step - loss: 0.6129 - accuracy: 0.7522\n",
      "Epoch 379/500\n",
      "3918/3918 [==============================] - 0s 60us/step - loss: 0.6325 - accuracy: 0.7414\n",
      "Epoch 380/500\n",
      "3918/3918 [==============================] - 0s 56us/step - loss: 0.6239 - accuracy: 0.7402\n",
      "Epoch 381/500\n",
      "3918/3918 [==============================] - 0s 58us/step - loss: 0.6162 - accuracy: 0.7478\n",
      "Epoch 382/500\n",
      "3918/3918 [==============================] - 0s 57us/step - loss: 0.6508 - accuracy: 0.7282\n",
      "Epoch 383/500\n",
      "3918/3918 [==============================] - 0s 59us/step - loss: 0.6370 - accuracy: 0.7366\n",
      "Epoch 384/500\n",
      "3918/3918 [==============================] - 0s 56us/step - loss: 0.6319 - accuracy: 0.7399\n",
      "Epoch 385/500\n",
      "3918/3918 [==============================] - 0s 57us/step - loss: 0.6178 - accuracy: 0.7506\n",
      "Epoch 386/500\n",
      "3918/3918 [==============================] - 0s 57us/step - loss: 0.6118 - accuracy: 0.7560\n",
      "Epoch 387/500\n",
      "3918/3918 [==============================] - 0s 63us/step - loss: 0.6173 - accuracy: 0.7473\n",
      "Epoch 388/500\n",
      "3918/3918 [==============================] - 0s 79us/step - loss: 0.6168 - accuracy: 0.7473\n",
      "Epoch 389/500\n",
      "3918/3918 [==============================] - 0s 60us/step - loss: 0.6130 - accuracy: 0.7542\n",
      "Epoch 390/500\n",
      "3918/3918 [==============================] - 0s 64us/step - loss: 0.6304 - accuracy: 0.7402\n",
      "Epoch 391/500\n",
      "3918/3918 [==============================] - 0s 61us/step - loss: 0.6135 - accuracy: 0.7532\n",
      "Epoch 392/500\n",
      "3918/3918 [==============================] - 0s 58us/step - loss: 0.6052 - accuracy: 0.7519\n",
      "Epoch 393/500\n",
      "3918/3918 [==============================] - 0s 57us/step - loss: 0.6305 - accuracy: 0.7458\n",
      "Epoch 394/500\n",
      "3918/3918 [==============================] - 0s 58us/step - loss: 0.6165 - accuracy: 0.7412 0s - loss: 0.5912 - accuracy\n",
      "Epoch 395/500\n",
      "3918/3918 [==============================] - 0s 56us/step - loss: 0.6150 - accuracy: 0.7473\n",
      "Epoch 396/500\n",
      "3918/3918 [==============================] - 0s 59us/step - loss: 0.6055 - accuracy: 0.7568\n",
      "Epoch 397/500\n",
      "3918/3918 [==============================] - 0s 62us/step - loss: 0.6296 - accuracy: 0.7440\n",
      "Epoch 398/500\n",
      "3918/3918 [==============================] - 0s 60us/step - loss: 0.6268 - accuracy: 0.7420\n",
      "Epoch 399/500\n",
      "3918/3918 [==============================] - 0s 57us/step - loss: 0.6258 - accuracy: 0.7443\n",
      "Epoch 400/500\n",
      "3918/3918 [==============================] - 0s 58us/step - loss: 0.6274 - accuracy: 0.7356 0s - loss: 0.6044 - accuracy: 0.\n",
      "Epoch 401/500\n",
      "3918/3918 [==============================] - 0s 61us/step - loss: 0.6261 - accuracy: 0.7489\n",
      "Epoch 402/500\n",
      "3918/3918 [==============================] - 0s 57us/step - loss: 0.6149 - accuracy: 0.7453\n",
      "Epoch 403/500\n",
      "3918/3918 [==============================] - 0s 63us/step - loss: 0.6273 - accuracy: 0.7414\n",
      "Epoch 404/500\n",
      "3918/3918 [==============================] - 0s 60us/step - loss: 0.6100 - accuracy: 0.7478\n",
      "Epoch 405/500\n",
      "3918/3918 [==============================] - 0s 59us/step - loss: 0.6229 - accuracy: 0.7481\n",
      "Epoch 406/500\n",
      "3918/3918 [==============================] - 0s 57us/step - loss: 0.6217 - accuracy: 0.7473\n",
      "Epoch 407/500\n",
      "3918/3918 [==============================] - 0s 56us/step - loss: 0.6153 - accuracy: 0.7509\n",
      "Epoch 408/500\n",
      "3918/3918 [==============================] - 0s 60us/step - loss: 0.6248 - accuracy: 0.7443\n",
      "Epoch 409/500\n",
      "3918/3918 [==============================] - 0s 56us/step - loss: 0.6162 - accuracy: 0.7552\n",
      "Epoch 410/500\n",
      "3918/3918 [==============================] - 0s 57us/step - loss: 0.6198 - accuracy: 0.7522\n",
      "Epoch 411/500\n",
      "3918/3918 [==============================] - 0s 57us/step - loss: 0.6047 - accuracy: 0.7534\n",
      "Epoch 412/500\n",
      "3918/3918 [==============================] - 0s 56us/step - loss: 0.6302 - accuracy: 0.7399\n",
      "Epoch 413/500\n",
      "3918/3918 [==============================] - 0s 56us/step - loss: 0.6084 - accuracy: 0.7455\n",
      "Epoch 414/500\n",
      "3918/3918 [==============================] - 0s 58us/step - loss: 0.6075 - accuracy: 0.7517\n",
      "Epoch 415/500\n",
      "3918/3918 [==============================] - 0s 60us/step - loss: 0.6066 - accuracy: 0.7458\n",
      "Epoch 416/500\n",
      "3918/3918 [==============================] - 0s 57us/step - loss: 0.5862 - accuracy: 0.7542\n",
      "Epoch 417/500\n",
      "3918/3918 [==============================] - 0s 59us/step - loss: 0.6014 - accuracy: 0.7552\n",
      "Epoch 418/500\n",
      "3918/3918 [==============================] - 0s 57us/step - loss: 0.6079 - accuracy: 0.7570\n",
      "Epoch 419/500\n",
      "3918/3918 [==============================] - 0s 62us/step - loss: 0.6102 - accuracy: 0.7568\n",
      "Epoch 420/500\n",
      "3918/3918 [==============================] - 0s 57us/step - loss: 0.6129 - accuracy: 0.7542\n",
      "Epoch 421/500\n",
      "3918/3918 [==============================] - 0s 56us/step - loss: 0.6020 - accuracy: 0.7573\n",
      "Epoch 422/500\n",
      "3918/3918 [==============================] - 0s 57us/step - loss: 0.6064 - accuracy: 0.7529\n",
      "Epoch 423/500\n",
      "3918/3918 [==============================] - 0s 56us/step - loss: 0.6148 - accuracy: 0.7386\n",
      "Epoch 424/500\n",
      "3918/3918 [==============================] - 0s 58us/step - loss: 0.6045 - accuracy: 0.7642\n",
      "Epoch 425/500\n",
      "3918/3918 [==============================] - 0s 56us/step - loss: 0.5956 - accuracy: 0.7611\n",
      "Epoch 426/500\n",
      "3918/3918 [==============================] - 0s 55us/step - loss: 0.5955 - accuracy: 0.7529\n",
      "Epoch 427/500\n",
      "3918/3918 [==============================] - 0s 56us/step - loss: 0.6001 - accuracy: 0.7644\n",
      "Epoch 428/500\n",
      "3918/3918 [==============================] - 0s 58us/step - loss: 0.6173 - accuracy: 0.7550\n",
      "Epoch 429/500\n",
      "3918/3918 [==============================] - 0s 60us/step - loss: 0.6149 - accuracy: 0.7540\n",
      "Epoch 430/500\n",
      "3918/3918 [==============================] - 0s 59us/step - loss: 0.6160 - accuracy: 0.7478\n",
      "Epoch 431/500\n",
      "3918/3918 [==============================] - 0s 64us/step - loss: 0.6248 - accuracy: 0.7425\n",
      "Epoch 432/500\n",
      "3918/3918 [==============================] - 0s 68us/step - loss: 0.6030 - accuracy: 0.7466\n",
      "Epoch 433/500\n",
      "3918/3918 [==============================] - 0s 62us/step - loss: 0.5926 - accuracy: 0.7583\n",
      "Epoch 434/500\n",
      "3918/3918 [==============================] - 0s 59us/step - loss: 0.6224 - accuracy: 0.7519\n",
      "Epoch 435/500\n",
      "3918/3918 [==============================] - 0s 60us/step - loss: 0.6166 - accuracy: 0.7591\n",
      "Epoch 436/500\n",
      "3918/3918 [==============================] - 0s 57us/step - loss: 0.6071 - accuracy: 0.7486\n",
      "Epoch 437/500\n",
      "3918/3918 [==============================] - 0s 59us/step - loss: 0.6132 - accuracy: 0.7588\n",
      "Epoch 438/500\n",
      "3918/3918 [==============================] - 0s 58us/step - loss: 0.6049 - accuracy: 0.7519\n",
      "Epoch 439/500\n",
      "3918/3918 [==============================] - 0s 61us/step - loss: 0.6008 - accuracy: 0.7504\n",
      "Epoch 440/500\n",
      "3918/3918 [==============================] - 0s 58us/step - loss: 0.6059 - accuracy: 0.7570\n",
      "Epoch 441/500\n",
      "3918/3918 [==============================] - 0s 59us/step - loss: 0.6127 - accuracy: 0.7588\n",
      "Epoch 442/500\n",
      "3918/3918 [==============================] - 0s 58us/step - loss: 0.6175 - accuracy: 0.7486\n",
      "Epoch 443/500\n",
      "3918/3918 [==============================] - 0s 57us/step - loss: 0.6011 - accuracy: 0.7616\n",
      "Epoch 444/500\n",
      "3918/3918 [==============================] - 0s 58us/step - loss: 0.5967 - accuracy: 0.7611\n",
      "Epoch 445/500\n",
      "3918/3918 [==============================] - 0s 58us/step - loss: 0.6200 - accuracy: 0.7471\n",
      "Epoch 446/500\n",
      "3918/3918 [==============================] - 0s 60us/step - loss: 0.6059 - accuracy: 0.7468\n",
      "Epoch 447/500\n",
      "3918/3918 [==============================] - 0s 57us/step - loss: 0.6273 - accuracy: 0.7392\n",
      "Epoch 448/500\n",
      "3918/3918 [==============================] - 0s 61us/step - loss: 0.6137 - accuracy: 0.7491\n",
      "Epoch 449/500\n",
      "3918/3918 [==============================] - 0s 67us/step - loss: 0.6031 - accuracy: 0.7524\n",
      "Epoch 450/500\n",
      "3918/3918 [==============================] - 0s 60us/step - loss: 0.6144 - accuracy: 0.7532\n",
      "Epoch 451/500\n",
      "3918/3918 [==============================] - 0s 60us/step - loss: 0.6187 - accuracy: 0.7458\n",
      "Epoch 452/500\n",
      "3918/3918 [==============================] - 0s 65us/step - loss: 0.6063 - accuracy: 0.7583\n",
      "Epoch 453/500\n",
      "3918/3918 [==============================] - 0s 59us/step - loss: 0.6067 - accuracy: 0.7565\n",
      "Epoch 454/500\n",
      "3918/3918 [==============================] - 0s 59us/step - loss: 0.6120 - accuracy: 0.7460\n",
      "Epoch 455/500\n",
      "3918/3918 [==============================] - 0s 61us/step - loss: 0.6079 - accuracy: 0.7486\n",
      "Epoch 456/500\n",
      "3918/3918 [==============================] - 0s 58us/step - loss: 0.6395 - accuracy: 0.7473\n",
      "Epoch 457/500\n",
      "3918/3918 [==============================] - 0s 57us/step - loss: 0.6070 - accuracy: 0.7547\n",
      "Epoch 458/500\n",
      "3918/3918 [==============================] - 0s 62us/step - loss: 0.5862 - accuracy: 0.7565\n",
      "Epoch 459/500\n",
      "3918/3918 [==============================] - 0s 57us/step - loss: 0.6132 - accuracy: 0.7568\n",
      "Epoch 460/500\n",
      "3918/3918 [==============================] - 0s 58us/step - loss: 0.5876 - accuracy: 0.7711\n",
      "Epoch 461/500\n",
      "3918/3918 [==============================] - 0s 60us/step - loss: 0.6215 - accuracy: 0.7486\n",
      "Epoch 462/500\n",
      "3918/3918 [==============================] - 0s 62us/step - loss: 0.5983 - accuracy: 0.7547\n",
      "Epoch 463/500\n",
      "3918/3918 [==============================] - 0s 58us/step - loss: 0.6070 - accuracy: 0.7471\n",
      "Epoch 464/500\n",
      "3918/3918 [==============================] - 0s 56us/step - loss: 0.6086 - accuracy: 0.7545\n",
      "Epoch 465/500\n",
      "3918/3918 [==============================] - 0s 59us/step - loss: 0.6197 - accuracy: 0.7527\n",
      "Epoch 466/500\n",
      "3918/3918 [==============================] - 0s 60us/step - loss: 0.5840 - accuracy: 0.7662\n",
      "Epoch 467/500\n",
      "3918/3918 [==============================] - 0s 60us/step - loss: 0.6082 - accuracy: 0.7557\n",
      "Epoch 468/500\n",
      "3918/3918 [==============================] - 0s 57us/step - loss: 0.6128 - accuracy: 0.7542\n",
      "Epoch 469/500\n",
      "3918/3918 [==============================] - 0s 59us/step - loss: 0.6008 - accuracy: 0.7586\n",
      "Epoch 470/500\n",
      "3918/3918 [==============================] - 0s 65us/step - loss: 0.6032 - accuracy: 0.7601\n",
      "Epoch 471/500\n",
      "3918/3918 [==============================] - 0s 67us/step - loss: 0.6158 - accuracy: 0.7565\n",
      "Epoch 472/500\n",
      "3918/3918 [==============================] - 0s 65us/step - loss: 0.6099 - accuracy: 0.7511\n",
      "Epoch 473/500\n",
      "3918/3918 [==============================] - 0s 63us/step - loss: 0.5901 - accuracy: 0.7598\n",
      "Epoch 474/500\n",
      "3918/3918 [==============================] - 0s 61us/step - loss: 0.6280 - accuracy: 0.7522\n",
      "Epoch 475/500\n",
      "3918/3918 [==============================] - 0s 58us/step - loss: 0.5942 - accuracy: 0.7616\n",
      "Epoch 476/500\n",
      "3918/3918 [==============================] - 0s 56us/step - loss: 0.5864 - accuracy: 0.7649\n",
      "Epoch 477/500\n",
      "3918/3918 [==============================] - 0s 60us/step - loss: 0.5813 - accuracy: 0.7652\n",
      "Epoch 478/500\n",
      "3918/3918 [==============================] - 0s 64us/step - loss: 0.5992 - accuracy: 0.7606\n",
      "Epoch 479/500\n",
      "3918/3918 [==============================] - 0s 64us/step - loss: 0.5983 - accuracy: 0.7511\n",
      "Epoch 480/500\n",
      "3918/3918 [==============================] - 0s 58us/step - loss: 0.6034 - accuracy: 0.7575\n",
      "Epoch 481/500\n",
      "3918/3918 [==============================] - 0s 61us/step - loss: 0.5838 - accuracy: 0.7688\n",
      "Epoch 482/500\n",
      "3918/3918 [==============================] - 0s 61us/step - loss: 0.6304 - accuracy: 0.7514\n",
      "Epoch 483/500\n",
      "3918/3918 [==============================] - 0s 64us/step - loss: 0.5856 - accuracy: 0.7660\n",
      "Epoch 484/500\n",
      "3918/3918 [==============================] - 0s 67us/step - loss: 0.5800 - accuracy: 0.7690\n",
      "Epoch 485/500\n",
      "3918/3918 [==============================] - 0s 62us/step - loss: 0.6026 - accuracy: 0.7570\n",
      "Epoch 486/500\n",
      "3918/3918 [==============================] - 0s 58us/step - loss: 0.5872 - accuracy: 0.7629\n",
      "Epoch 487/500\n",
      "3918/3918 [==============================] - 0s 57us/step - loss: 0.6160 - accuracy: 0.7511\n",
      "Epoch 488/500\n",
      "3918/3918 [==============================] - 0s 62us/step - loss: 0.5889 - accuracy: 0.7586\n",
      "Epoch 489/500\n",
      "3918/3918 [==============================] - 0s 57us/step - loss: 0.6141 - accuracy: 0.7486\n",
      "Epoch 490/500\n",
      "3918/3918 [==============================] - 0s 59us/step - loss: 0.6137 - accuracy: 0.7522\n",
      "Epoch 491/500\n",
      "3918/3918 [==============================] - 0s 64us/step - loss: 0.6192 - accuracy: 0.7422\n",
      "Epoch 492/500\n",
      "3918/3918 [==============================] - 0s 59us/step - loss: 0.5983 - accuracy: 0.7504\n",
      "Epoch 493/500\n",
      "3918/3918 [==============================] - 0s 60us/step - loss: 0.5910 - accuracy: 0.7611 0s - loss: 0.5823 - accuracy: 0.\n",
      "Epoch 494/500\n",
      "3918/3918 [==============================] - 0s 58us/step - loss: 0.6050 - accuracy: 0.7568\n",
      "Epoch 495/500\n",
      "3918/3918 [==============================] - 0s 59us/step - loss: 0.6024 - accuracy: 0.7586\n",
      "Epoch 496/500\n",
      "3918/3918 [==============================] - 0s 63us/step - loss: 0.6070 - accuracy: 0.7514\n",
      "Epoch 497/500\n",
      "3918/3918 [==============================] - 0s 59us/step - loss: 0.6167 - accuracy: 0.7511\n",
      "Epoch 498/500\n",
      "3918/3918 [==============================] - 0s 60us/step - loss: 0.5930 - accuracy: 0.7580\n",
      "Epoch 499/500\n",
      "3918/3918 [==============================] - 0s 64us/step - loss: 0.5874 - accuracy: 0.7524\n",
      "Epoch 500/500\n",
      "3918/3918 [==============================] - 0s 60us/step - loss: 0.5766 - accuracy: 0.7621\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x23a8a077788>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the model in 32 batch size and 100-500 epochs\n",
    "batch_size = 32\n",
    "epochs = 500\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction an accuracy on train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.1718430e-06, 1.9082200e-02, 1.7298785e-01, ..., 7.8111440e-03,\n",
       "        9.6601213e-04, 2.7852937e-07],\n",
       "       [6.6531220e-06, 1.0066050e-02, 3.9382866e-01, ..., 3.7806069e-03,\n",
       "        3.4130546e-06, 2.3696150e-07],\n",
       "       [2.1752027e-07, 1.3251359e-03, 8.3154637e-01, ..., 2.2936314e-02,\n",
       "        9.1041602e-06, 2.7973510e-10],\n",
       "       ...,\n",
       "       [5.0088797e-08, 1.7509298e-04, 2.7553755e-01, ..., 6.1030814e-04,\n",
       "        7.4141792e-07, 3.9641679e-10],\n",
       "       [3.4426066e-08, 1.0336059e-04, 5.5961750e-02, ..., 1.4402276e-01,\n",
       "        8.9645931e-05, 1.2490463e-07],\n",
       "       [5.2260351e-05, 1.3131969e-05, 2.1619591e-01, ..., 2.6300631e-08,\n",
       "        8.7757096e-10, 1.7672406e-15]], dtype=float32)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4893</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4894</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4895</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4896</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4897</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4898 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      3  4  5  6  7  8  9\n",
       "0     0  0  0  1  0  0  0\n",
       "1     0  0  0  1  0  0  0\n",
       "2     0  0  0  1  0  0  0\n",
       "3     0  0  0  1  0  0  0\n",
       "4     0  0  0  1  0  0  0\n",
       "...  .. .. .. .. .. .. ..\n",
       "4893  0  0  0  1  0  0  0\n",
       "4894  0  0  1  0  0  0  0\n",
       "4895  0  0  0  1  0  0  0\n",
       "4896  0  0  0  0  1  0  0\n",
       "4897  0  0  0  1  0  0  0\n",
       "\n",
       "[4898 rows x 7 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 3, 2, ..., 3, 3, 3], dtype=int64)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_ = y_pred.argmax(axis=1)\n",
    "y_pred_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([3, 4, 5, 6, 7, 8, 9], dtype='int64')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_y.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([6, 6, 5, 6, 6, 6, 6, 6, 7, 5,\n",
       "            ...\n",
       "            6, 6, 7, 5, 6, 6, 5, 6, 6, 6],\n",
       "           dtype='int64', length=3918)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_product = dummy_y.columns[y_pred_]\n",
    "y_pred_product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2480</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>665</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4197</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4461</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4435</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3095</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2896</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>691</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3336</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1926</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3918 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      3  4  5  6  7  8  9\n",
       "2480  0  0  1  0  0  0  0\n",
       "665   0  0  1  0  0  0  0\n",
       "4197  0  0  1  0  0  0  0\n",
       "4461  0  0  0  1  0  0  0\n",
       "4435  0  0  0  1  0  0  0\n",
       "...  .. .. .. .. .. .. ..\n",
       "3095  0  0  0  1  0  0  0\n",
       "2896  0  0  1  0  0  0  0\n",
       "691   0  0  0  1  0  0  0\n",
       "3336  0  0  0  1  0  0  0\n",
       "1926  0  0  0  1  0  0  0\n",
       "\n",
       "[3918 rows x 7 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, ..., 3, 3, 3], dtype=int64)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_ = y_train.values.argmax(axis=1)\n",
    "y_train_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9017355793772333"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy = accuracy_score(y_train_, y_pred_)\n",
    "accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  13,    0,    0,    1,    0,    0,    0],\n",
       "       [   0,   96,   16,   10,    0,    0,    0],\n",
       "       [   0,    4, 1008,  132,   11,    0,    0],\n",
       "       [   0,    1,   60, 1651,   61,    2,    0],\n",
       "       [   0,    0,    4,   44,  660,    1,    0],\n",
       "       [   0,    0,    1,    2,   35,  100,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    5]], dtype=int64)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_train_, y_pred_)\n",
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction and accuracy on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred_ = y_pred.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_ = y_test.values.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6265306122448979"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "accuracy = accuracy_score(y_test_, y_pred_)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1,   0,   2,   3,   0,   0],\n",
       "       [  1,   7,  19,  13,   1,   0],\n",
       "       [  0,   5, 195,  93,   9,   0],\n",
       "       [  1,   2,  64, 295,  56,   5],\n",
       "       [  0,   0,   5,  52, 108,   6],\n",
       "       [  0,   0,   1,   8,  20,   8]], dtype=int64)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test_, y_pred_)\n",
    "cm"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
